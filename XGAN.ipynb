{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WVSKl21x4sur"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgQ0Ops35BPq"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","\n","import os\n","import cv2\n","import json\n","import h5py\n","import pandas, numpy, random\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tD50QkfoKak"},"outputs":[],"source":["# Check HDF5 file\n","h5py_dir = '/content/drive/My Drive/Colab Notebooks/Data/train.h5py'\n","\n","with h5py.File(h5py_dir, 'r') as hdf:\n","    if 'complete' in hdf and 'local' in hdf and 'parameters' in hdf:\n","        print(f\"Number of in_images: {len(hdf['complete'])}\")\n","        print(f\"Number of local: {len(hdf['local'])}\")\n","        print(f\"Number of parameters: {len(hdf['parameters'])}\")\n","    else:\n","        print(\"Expected datasets not found in the HDF5 file.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1vdC7lSYx-ou"},"outputs":[],"source":["# Check if CUDA is available. If yes, set default tensor type to cuda\n","\n","if torch.cuda.is_available():\n","    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n","    print(\"using cuda:\", torch.cuda.get_device_name(0))\n","    pass\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BEZgbZpkVzWS"},"outputs":[],"source":["class View(nn.Module):\n","    # A variation of .view that can be exectued inside nn.Sequential()\n","    def __init__(self, shape):\n","        super().__init__()\n","        self.shape = shape\n","\n","    def forward(self, x):\n","        return x.view(self.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3FlFi-CSr7A"},"outputs":[],"source":["def in_painting(in_image, coordinate, left_patch, right_patch):\n","\n","    patched_image = in_image\n","\n","    # Resize left eye\n","    lx, ly = int(coordinate[0].item()), int(coordinate[1].item())\n","    lw, lh = int(coordinate[2].item()), int(coordinate[3].item())\n","    up = max(0, int(ly - lh / 2))\n","    down = min(80, int(ly + lh / 2) + 1)\n","    lh = down - up\n","    left_patch_resized = cv2.resize(left_patch, (lw + 1, lh))\n","\n","    # In paint the left eye\n","    patched_image[up:down, int(lx - lw / 2):(int(lx - lw / 2) + lw + 1)] = left_patch_resized\n","\n","    # Resize the right eye\n","    rx, ry = int(coordinate[4].item()), int(coordinate[5].item())\n","    rw, rh = int(coordinate[6].item()), int(coordinate[7].item())\n","    up = max(0, int(ry - rh / 2))\n","    down = min(80, int(ry + rh / 2) + 1)\n","    rh = down - up\n","    right_patch_resized = cv2.resize(right_patch, (rw + 1, rh))\n","\n","    # In paint the right eye\n","    patched_image[up:down, int(rx - rw / 2):(int(rx - rw / 2) + rw + 1)] = right_patch_resized\n","\n","    return patched_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NWyBUwkitWb5"},"outputs":[],"source":["class Celeb_ID_Dataset(Dataset):\n","\n","    def __init__(self, file_path):\n","        self.file_path = file_path\n","        self.file_object = h5py.File(file_path, 'r')\n","        self.data_len = len(self.file_object['complete'])\n","\n","    def __len__(self):\n","        return self.data_len\n","\n","    def __getitem__(self, idx):\n","        complete = self.file_object['complete'][idx]\n","        local = self.file_object['local'][idx]\n","        parameter = self.file_object['parameters'][idx]\n","\n","        complete = torch.FloatTensor(complete).permute(2,0,1).view(3, 80, 256) / 255.0\n","        local = torch.FloatTensor(local).permute(2,0,1).view(3, 100, 200) / 255.0\n","        param = torch.FloatTensor(parameter)\n","\n","        return complete, local, param\n","\n","    def __del__(self):\n","        self.file_object.close()\n","\n","# Create Dataset and Dataloader object\n","file_path = '/content/drive/My Drive/Colab Notebooks/Data/train.h5py'\n","dataset = Celeb_ID_Dataset(file_path)\n","params = {'batch_size': 32, 'shuffle': True, 'generator':torch.Generator(device='cuda')}\n","dataloader = DataLoader(dataset, **params)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mf5ea_QZH6tR"},"outputs":[],"source":["class Discriminator(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Global Discriminator\n","        self.global_discriminator = nn.Sequential(\n","            # The input should be a 80 * 256 * 3 image that has been patched\n","            nn.Conv2d(3, 128, kernel_size=(9, 27), stride=2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(128, 64, kernel_size=(7, 27), stride=2),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(64, 3, kernel_size=(1, 6), stride=2),\n","            nn.BatchNorm2d(3),\n","            nn.LeakyReLU(0.2),\n","            View((32, 3*8*20)),\n","            nn.Linear(3*8*20, 100)\n","            # The output should be a 1D tensor with 100 elements\n","        )\n","\n","        # Local Discriminator\n","        self.local_discriminator = nn.Sequential(\n","            # The input should be a 100 * 200 * 3 image\n","            nn.Conv2d(3, 128, kernel_size=5, stride=2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(128, 64, kernel_size=5, stride=2),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(64, 3, kernel_size=(4, 8), stride=2),\n","            nn.BatchNorm2d(3),\n","            nn.LeakyReLU(0.2),\n","            View((32, 3*10*20)),\n","            nn.Linear(3*10*20, 100)\n","            # The output should be a 1D tensor with 100 elements\n","        )\n","\n","        # The final layer with one neuron whose output is a scalar and a Sigmoid activation\n","        self.concat_fc = nn.Sequential(\n","            nn.Linear(200, 1),\n","            nn.Sigmoid()\n","        )\n","\n","        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n","\n","        self.counter = 0\n","        self.progress = []\n","        pass\n","\n","    def forward(self, global_x, local_x):\n","        # Concatenate the global and local discriminator outputs\n","        global_output = self.global_discriminator(global_x)\n","        local_output = self.local_discriminator(local_x)\n","        output = torch.cat((global_output, local_output), dim=1)\n","        output = self.concat_fc(output)\n","        return output\n","\n","    def cal_bce_loss(self, d_score, label):\n","        # BCE loss of the concatenated local and global discriminator\n","        alpha = 5e-4\n","        d_loss = F.binary_cross_entropy(d_score, label)\n","        return alpha * d_loss\n","\n","    def cal_mse_loss(self, local_x, ur_local):\n","        # MSE loss of the global image\n","        local_loss = F.mse_loss(local_x, ur_local, reduction='mean')\n","        return local_loss\n","\n","    def train_on_true(self, global_x, local_x):\n","        # Calculate d_score and the total loss\n","        d_score = self.forward(global_x, local_x)\n","        label = torch.ones(d_score.shape)\n","        loss = self.cal_bce_loss(d_score, label)\n","\n","        # increase counter and accumulate error every 10\n","        self.counter += 1;\n","        if (self.counter % 10 == 0):\n","            self.progress.append(loss.item())\n","            pass\n","        if (self.counter % 1000 == 0):\n","            print(\"counter = \", self.counter)\n","            pass\n","\n","        # Reset gradients, perform back propagation and update weights\n","        self.optimiser.zero_grad()\n","        loss.backward()\n","        self.optimiser.step()\n","        pass\n","\n","    def train_on_fake(self, global_x, local_x, local_y):\n","        # Calculate d_score and the total loss\n","        d_score = self.forward(global_x, local_x)\n","        label = torch.zeros(d_score.shape)\n","        bce_loss = self.cal_bce_loss(d_score, label)\n","        mse_loss = self.cal_mse_loss(local_x, local_y)\n","\n","        loss = bce_loss + mse_loss\n","\n","        # increase counter and accumulate error every 10\n","        self.counter += 1;\n","        if (self.counter % 10 == 0):\n","            self.progress.append(loss.item())\n","            pass\n","        if (self.counter % 1000 == 0):\n","            print(\"counter = \", self.counter)\n","            pass\n","\n","        # Reset gradients, perform back propagation and update weights\n","        self.optimiser.zero_grad()\n","        loss.backward()\n","        self.optimiser.step()\n","        pass\n","\n","    def plot_progress(self):\n","        df = pandas.DataFrame(self.progress, columns=['loss'])\n","        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.1, 0.02))\n","        pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ch17hOknmbH5"},"outputs":[],"source":["class Generator(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.concentration = nn.Sequential(\n","            # The input should be a 1 * 3 * 80 * 256 image\n","            nn.Conv2d(3, 128, kernel_size=(4, 27), stride=2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(128, 128, kernel_size=(3, 27), stride=2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(128, 3, kernel_size=(1, 7), stride=2),\n","            nn.BatchNorm2d(3),\n","            nn.LeakyReLU(0.2)\n","            # This gives a convolved image of shape 1 * 3 * 10 * 20\n","        )\n","\n","        self.model = nn.Sequential(\n","            # The input should be a 1 * 3 * 10 * 20 tensor\n","            nn.ConvTranspose2d(3, 64, kernel_size=5, stride=2),\n","            nn.BatchNorm2d(64),\n","            nn.LeakyReLU(0.2),\n","            nn.ConvTranspose2d(64, 128, kernel_size=5, stride=2),\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2),\n","            nn.ConvTranspose2d(128, 3, kernel_size=(4, 24), stride=2),\n","            nn.BatchNorm2d(3),\n","            nn.Sigmoid()\n","            # The output should be a 1 * 3 * 100 * 200 image of the in painting region\n","        )\n","\n","        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n","\n","        self.counter = 0\n","        self.progress = []\n","        pass\n","\n","    def forward(self, inputs):\n","        convolved_image = self.concentration(inputs)\n","        return self.model(convolved_image)\n","\n","    def train(self, D, global_x, local_x, local_y):\n","        # Calculate d_score and the total loss\n","        d_score = D.forward(global_x, local_x)\n","        label = torch.ones(d_score.shape)\n","        bce_loss = D.cal_bce_loss(d_score, label)\n","        mse_loss = D.cal_mse_loss(local_x, local_y)\n","\n","        loss = bce_loss + mse_loss\n","\n","        # Increase counter and accumulate error every 10\n","        self.counter += 1\n","        if (self.counter % 10 == 0):\n","            self.progress.append(loss.item())\n","            pass\n","\n","        # Reset gradients, perform back propagation and update weights\n","        self.optimiser.zero_grad()\n","        loss.backward()\n","        self.optimiser.step()\n","        pass\n","\n","    def plot_progress(self):\n","        df = pandas.DataFrame(self.progress, columns=['loss'])\n","        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.1, 0.02))\n","        pass\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6LjK_UjLQZhu"},"outputs":[],"source":["def process_image(batch_complete, batch_patches, batch_parameter):\n","    # Unpack the batch, perform individual operation on each and repack in to batch\n","    patched = []\n","    for i in range(batch_patches.size(0)):\n","        in_image = batch_complete[i].unsqueeze(0).permute(0,2,3,1).view(80,256,3).cpu().numpy()\n","        raw_patches = batch_patches[i].unsqueeze(0).permute(0,2,3,1).view(100,200,3).detach().cpu().numpy()\n","        coordinate = batch_parameter[i].unsqueeze(1)\n","\n","        patches = (raw_patches).clip(0, 1).astype(numpy.float32)\n","        left_patch = patches[0:100, 0:100, ...]\n","        right_patch = patches[0:100, 100:200, ...]\n","\n","        completion = in_painting(in_image, coordinate, left_patch, right_patch)\n","        patched.append(torch.FloatTensor(completion).permute(2,0,1).view(3, 80, 256))\n","\n","    # Re-pack to mini-batch on GPU device\n","    return torch.stack(patched).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fff592kS9yU"},"outputs":[],"source":["# Create Discriminator and Generator\n","D = Discriminator().to(device)\n","G = Generator().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zQUOlh-32Pu7"},"outputs":[],"source":["# Load parameters (opt)\n","D.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/D_epoch_25.pth'))\n","G.load_state_dict(torch.load('/content/drive/My Drive/Colab Notebooks/G_epoch_25.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TFGVQBpfAXx"},"outputs":[],"source":["%%time\n","\n","# Train the Network\n","\n","current_epoch = 80\n","itr_epoch = 20\n","batch_size = 32\n","\n","for epoch in range(itr_epoch):\n","    current_epoch += 1\n","    print(\"epoch = \", current_epoch)\n","\n","    for batch_complete, batch_local, batch_parameter in dataloader:\n","        # Move data to CUDA device\n","        batch_complete = batch_complete.to(device)\n","        batch_local = batch_local.to(device)\n","\n","        # Train the discriminator on true *\n","        D.train_on_true(batch_complete, batch_local)\n","\n","        # In paint with noise as input tensor\n","        batch_noise = 0.2 * torch.randn(batch_size, 3, 100, 200)\n","        batch_input = process_image(batch_complete, batch_noise, batch_parameter)\n","\n","        # Generate patches and in-paint the images\n","        batch_patches = G.forward(batch_input)\n","        batch_completion = process_image(batch_complete, batch_patches, batch_parameter)\n","\n","        # Train the discriminator on fake (false) *\n","        local_x = batch_patches.detach()\n","        D.train_on_fake(batch_completion, local_x, batch_local)\n","\n","        # Train the generator *\n","        G.train(D, batch_completion, batch_patches, batch_local)\n","\n","    if (current_epoch % 5 == 0):\n","        # Save the model weights\n","        model_dir = '/content/drive/My Drive/Colab Notebooks/'\n","        D_name = 'D_epoch_{}.pth'.format(current_epoch)\n","        G_name = 'G_epoch_{}.pth'.format(current_epoch)\n","        torch.save(D.state_dict(), os.path.join(model_dir, D_name))\n","        torch.save(G.state_dict(), os.path.join(model_dir, G_name))\n","\n","        # Plot Progress\n","        # D.plot_progress()\n","        # G.plot_progress()\n","        pass\n","\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xVwbsVwKZhHy"},"outputs":[],"source":["# Save the model weights\n","model_dir = '/content/drive/My Drive/Colab Notebooks/'\n","\n","D_name = 'D_epoch_{}.pth'.format(current_epoch)\n","G_name = 'G_epoch_{}.pth'.format(current_epoch)\n","\n","torch.save(D.state_dict(), os.path.join(model_dir, D_name))\n","torch.save(G.state_dict(), os.path.join(model_dir, G_name))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oeubpRKd_Rmp"},"outputs":[],"source":["# Check the result after training\n","\n","fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n","\n","for batch_complete, batch_local, batch_parameter in dataloader:\n","    # Move data to CUDA device\n","    batch_complete = batch_complete.to(device)\n","    batch_local = batch_local.to(device)\n","\n","    # In paint with noise as input tensor\n","    batch_noise = 0.2 * torch.randn(32, 3, 100, 200)\n","    batch_input = process_image(batch_complete, batch_noise, batch_parameter)\n","\n","    # Generate patches and in-paint the images\n","    batch_patches = G.forward(batch_input)\n","    batch_completion = process_image(batch_complete, batch_patches, batch_parameter)\n","\n","    for i in range(batch_completion.size(0)):\n","        output = batch_completion[i].unsqueeze(0)\n","        input = batch_input[i].unsqueeze(0)\n","        local_y = batch_local[i].unsqueeze(0)\n","        raw_patches = batch_patches[i].unsqueeze(0)\n","        parameter = batch_parameter[i].unsqueeze(1)\n","\n","        output = output.permute(0,2,3,1).view(80,256,3).cpu().numpy()\n","        input = input.permute(0,2,3,1).view(80,256,3).cpu().numpy()\n","        local_y = local_y.permute(0,2,3,1).view(100,200,3).cpu().numpy()\n","        patches = raw_patches.permute(0,2,3,1).view(100,200,3).detach().cpu().numpy()\n","\n","        axs[0].imshow(patches, cmap='gray')\n","        axs[0].set_title(\"Patches\")\n","\n","        axs[1].imshow(local_y, cmap='gray')\n","        axs[1].set_title(\"Original\")\n","\n","        axs[2].imshow(input, cmap='gray')\n","        axs[2].set_title(\"Input\")\n","\n","        axs[3].imshow(output.clip(0, 1).astype(numpy.float32), cmap='gray')\n","        axs[3].set_title(\"Completion\")\n","\n","        break\n","\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2Jp72jyBcDE"},"outputs":[],"source":["# Plot discriminator error\n","D.plot_progress()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZf-ezSWBc37"},"outputs":[],"source":["# Plot generator error\n","G.plot_progress()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNySjK3phRK4"},"outputs":[],"source":["# Application\n","\n","fig, axes = plt.subplots(1, 2, figsize=(9, 6))\n","\n","# Taylor Swift\n","input_image = cv2.imread('/content/drive/My Drive/Colab Notebooks/Data/Test Image/TS.jpg')\n","parameter = numpy.array([[81,], [41,], [53,], [48,], [179,], [40,], [48,], [49,]])\n","\n","# Donald Trump\n","# input_image = cv2.imread('/content/drive/My Drive/Colab Notebooks/Data/Test Image/DT.jpg')\n","# parameter = numpy.array([[87,], [42,], [45,], [45,], [190,], [33,], [45,], [45,]])\n","\n","image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n","\n","gallery = []\n","gallery.append(image.copy())\n","\n","noise = 0.2 * torch.randn(100, 200, 3).cpu().numpy()\n","noise = (noise * 255).clip(0, 255).astype(numpy.uint8)\n","left = noise[0:100, 0:100, ...]\n","right = noise[0:100, 100:200, ...]\n","\n","input = in_painting(image, parameter, left, right)\n","batch_input = torch.FloatTensor(input).permute(2,0,1).view(3, 80, 256) / 255.0\n","batch_input = batch_input.repeat(32, 1, 1, 1).to(device)\n","batch_patches = G.forward(batch_input).detach()\n","\n","\n","for i in range(1):\n","    raw_patches = batch_patches[i].unsqueeze(0)\n","    gray_patches = raw_patches.permute(0,2,3,1).view(100,200,3).cpu().numpy()\n","    patches = (gray_patches * 255).clip(0, 255).astype(numpy.uint8)\n","\n","    left_patch = patches[0:100, 0:100, ...]\n","    right_patch = patches[0:100, 100:200, ...]\n","\n","    completion = in_painting(image, parameter, left_patch, right_patch)\n","    gallery.append(completion)\n","    pass\n","\n","axes = axes.flatten()\n","num = 0\n","for img, ax in zip(gallery, axes):\n","    ax.imshow(img)\n","    if num == 0:\n","        ax.set_title(\"Original\")\n","    else:\n","        ax.set_title(f\"Completion\")\n","    ax.axis('off')\n","    num += 1\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","provenance":[],"authorship_tag":"ABX9TyNRqQO+gctTJrHU19lZfkzs"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}